\section{Recommendations for Practice, and Future Improvements}
\label{c7:sec:future_research}
Based on the work done in this thesis, we have certain recommendation for practitioners as well a list of improvements that may be researched in future. We next provide these recommendations and improvements in each of the four steps of creating invasive test schedules (defined in Chapter~\ref{c1:subsec:goal}). These are, namely, processing the observed data of the patient, choosing the reward/utility/loss function and the corresponding clinical parameters, comparing proposed personalized schedules with currently practiced schedules, and implementing personalized schedules in a computer application for practitioners.

\subsection{Observed Data of the Patient}
Our overall recommendation while developing a model for personalized schedules is to focus on the predictive performance of the model. For example, in the prostate cancer surveillance joint model, we used a limited set of predictors (e.g., PSA value and velocity). However, this did not necessarily lead to the model with the best prediction error, and/or capacity of discrimination (e.g., the area under the receiver operating characteristic curve) between patients who are progressing and non-progressing patients. In this regard, although a joint model is a suitable candidate for modeling both longitudinal and time-to-event data, practitioners may also explore other models, and strive to achieve the best predictions. In addition, there are four broad areas of improvement in modeling observed data of the patient than the standard joint model we used.

\paragraph{Sampling error} In general invasive procedures such as biopsies are prone to sampling error, especially when the site for sampling the tissues is not chosen carefully. In this regard,~\citet{coley2017} have proposed a joint model that predicts the time of actual disease progression given the time of observed progression. Actual progression means progression in the absence of sampling error, e.g., progression based on complete tumor such as via surgical removal, rather than biopsy samples.

\paragraph{Inter-observer variation} Invasive test results are also prone to inter-observer variation. Models that have been proposed~\citep{balasubramanian2003estimation} to handle this problem require an estimate of the size and direction of the inter-observation variation. However, if the inter-observer variation for a test is inherently large, then overall model parameter estimates for risk of progression may also inflate.

\paragraph{Recurrent cancer} We did not consider the scenario of surveillance of recurrent occurrence of progression (e.g., recurrent breast cancer). Although, if a model predicts risk of progression while accounting for recurrent events~\citep{rizopoulos2012joint}, the scheduling methodology that we proposed may not change.

\paragraph{Competing-risks} In this work, we assumed all competing events to be non-informative censoring. However, treatment without progression or death may occur in a substantial number of patients. This affects our methodology in three ways. First, while creating risk-based schedules; second, during the calculation of the expected number of tests given a schedule; and third, in the calculation of expected time delay in detecting progression given a schedule. Among these, schedules based on cause-specific cumulative-risk may be alternatively obtained using the cumulative-incidence function~\citep{andrinopoulou2017combined, putter2007tutorial}. The expected number of tests requires a model in which all events are combined to form a composite event. This is because the occurrence of any of the competing events will stop surveillance. On the other hand, time delay in detecting progression may only be defined if progression occurs before any other competing event.

\subsection{Choice of Reward/Utility Function}
The majority of the scheduling methods we explored in this work optimized the expected value of a utility function. Although, another key aspect is the variance of the utility. This is because a schedule with sub-optimal expected utility but lower utility variance may seem more trustworthy owing to its consistency. For example, the squared loss has a high variance in delay in detecting progression despite having expected delay equal to zero (Chapter~\ref{c2}). Second, we relied on the number of invasive tests and time delay in detecting disease progression as measures of burden and benefit of scheduling an invasive test. However, it is also important to consider patient anxiety, risk of complications, risk of non-compliance, and quality-adjusted life-years (QALY). Among these, the reference measure in a cost-utility analysis is QALY~\citep{sassi2006calculating}. Although it can be included in the utility functions we proposed (Chapter~\ref{c4}), the biggest challenge is calculating QALYs correctly in different disease surveillance.

\paragraph{Optimizing the schedule of invasive tests and longitudinal outcomes together} In Chapters~\ref{c2} to~\ref{c5}, we optimized the schedule of invasive tests, whereas in Chapter~\ref{c6} we optimized the schedule of the longitudinal outcome. In diseases such as chronic heart failure (Chapter~\ref{c6}), being able to measure the longitudinal outcome also indicates the survival of the patient. This is because if the patient obtains the event (cardiac failure), the longitudinal outcome cannot be measured. Whereas in a disease such as Barrett's esophagus, longitudinal outcomes are also measured via endoscopy (invasive). Hence, there is no need to optimize the schedule of invasive tests and the longitudinal outcomes separately. Conversely, in prostate cancer active surveillance, longitudinal outcomes can be measured even after patient obtains progression because progression in prostate cancer active surveillance is a non-terminal event. Hence, an interesting question is if we can optimize both the schedule of invasive tests and multiple longitudinal measurements together. 

Optimizing the schedule of invasive tests and longitudinal outcomes together has the potential to reduce patient burden even further. However, it has certain caveats too. For example, in Chapter~\ref{c5}, we observed that PSA is not a strong indicator of progression. Thus, fewer PSA measurements will mean increased variance of estimates of cumulative-risk of progression. On the other hand, in diseases where the biomarker is a strong indicator of progression, measuring it less frequently may still provide reasonably accurate estimates of progression. Hence, our overall recommendation while pursuing this research problem is that for all longitudinal biomarkers, we first calculate a quantitative estimate of their burden (both financial and medical) and their predictive ability. Perhaps, optimal results can be obtained by employing a combination of, frequently measuring a cheaper but poor indicator of progression with infrequently measuring an expensive but reliable indicator of progression.

\subsection{Simulation of Invasive Test Randomized Clinical Trials}
While simulating hypothetical patients, we ignored the correlation between a patient's baseline features, and the patient's non-compliance to invasive tests. Generating correlated predictors will make the simulation cohort more realistic. Whereas, accounting for patient non-compliance to invasive tests will correct the currently likely over-estimated benefit of personalized schedules over fixed schedules.

\subsection{Linking Patient Databases with Web-interfaces for Personalized Schedules}
Risk-calculators for disease progression, including our web-application for prostate cancer surveillance patients, are not difficult to create given the current support for web-based technologies in the R framework. The larger challenge is linking the risk calculators with patient databases. We recommend the current industry standard of RESTful Web services~\citep{rodriguez2008restful} for this purpose. 