\section{Subgoals and Research Questions}
\label{c7:sec:subgoals}
\subsection{Statistical Modeling Framework to Process Observed Patient Data}
We used the framework of joint models for time-to-event and longitudinal data~\citep{rizopoulos2012joint,tsiatis2004joint} to process a patient's data and predict his patient's cumulative-risk of progression. We chose this for three main reasons. First, joint models utilize patient-specific random-effects and are hence inherently personalized. Second, they accommodate outcomes of various types, including longitudinally measured, baseline patient data, and results from previous invasive tests. Third, they update risk predictions automatically over follow-up as more patient data become available. 

There are some limitations of the joint models that we utilized. First, in our model, we selected predictors based on existing hypotheses regarding the clinical relevance of the predictors. However, such hypotheses can change with time, e.g., PSA velocity~\citep{vickers2014commentary}. An alternative is choosing model predictors based on their predictive ability. Second, we ignored competing-risk scenarios and estimated only cause-specific cumulative-risk of progression. Third, our model did not account for the sampling error and inter-observer variation in invasive test results. However, these limitations apply only to the model, i.e., the scheduling methodology remains the same, even if a better model is employed.

\subsection{Pros of Cons of Different Utility Functions}
\paragraph{Utility functions: squared and absolute loss, Parameter of interest: time of progression} In Chapter~\ref{c2}, we optimized two commonly used loss functions, namely, expected squared and absolute loss~\citep{robertBayesianChoice} for the time of progression to decide the time of the next invasive test. These loss functions plan an invasive test at the estimated mean (square loss) and median (absolute loss) time of progression of a patient. There are two limitations to this method. First, due to the limited follow-up period of real-world studies, only a restricted version of the mean time of progression can be calculated, which has no straightforward interpretation. Second, depending upon the standard deviation of the posterior predictive distribution of time of progression, the difference between the actual and mean time of progression can be substantial. Both mean and median time of progression may sound suitable when interpreted as the central tendency of the distribution for time of progression. However, they also represent the time at which a patient has a 50\% risk of progression, which may seem large clinically.

\paragraph{Utility function: multi-linear loss (risk-based tests), Parameter of interest: time of progression} Squared and absolute loss penalize equally a planned invasive test that exceeds or falls short of the time of progression. However, patients may weigh these two scenarios unequally, especially because multiple tests before the actual time of progression can be burdensome. In this regard, a multi-linear loss function (Chapter~\ref{c2}) can be used. This loss function plans a test at a time point at which the patient's risk of progression is equal to a particular risk threshold. Smaller risk thresholds plan a test earlier than higher risk thresholds. In other words, smaller risk thresholds penalize exceeding the time progression more than falling short of the time of progression. 

The main caveat in such risk-based test decisions (Chapter~\ref{c3}) is the choice of risk threshold. This threshold may be chosen by patients and/or doctors according to how they weigh the relative harms of doing an unnecessary test versus a missed disease progression (e.g., 10\% threshold means a 1:9 ratio) if the test is not conducted~\citep{vickers2006decision}. Threshold choice can also be partly data-driven, e.g., based on the threshold's estimated sensitivity and specificity of diagnosing progression. In this regard, it is also possible to choose risk thresholds using more sophisticated measures than just sensitivity or specificity, e.g., Youden's index, F1 score~\citep{lopez2014optimalcutpoints}. However, a critical limitation of such measures is that they may automatically select a risk threshold with clinically unsuitable sensitivity and specificity. Also, typically such measures are difficult to interpret.

\paragraph{Utility function: Partially observable Markov decision process (POMDP) value function} In Chapter~\ref{c4:appendix:pomdp} we explored the framework of POMDP to schedule invasive tests. The choice of POMDP was motivated by its wide usage in numerous optimal screening and surveillance test schedules for chronic diseases~\citep{steimle2017markov,denton2018optimization}, and especially for nearly all types of cancers~\citep{alagoz2010operations}. 

In general, POMDPs utilize estimates from previously conducted studies or surveys to build a disease state transition model. In this work, we did not have to rely on existing studies as we made a joint model for modeling the patient's disease state and the associated clinical data. We integrated joint models with POMDPs by replacing the Bayes-rule based belief (risk of disease progression, see Equation~\ref{c4:eq:belief_jm}) update of POMDPs, with the dynamic predictions~\citep{rizopoulos2017dynamic} of cumulative-risk of progression from joint models. This had the advantage that it also personalized the POMDP. Concerning the use of clinical data, POMDPs assume that the probability distribution of future longitudinal data adds extra information over observed data. However, we estimated the posterior probability distribution of future longitudinal data based on observed data using the joint model. Hence, sampling a new observation from the future distribution and using it to update belief adds no information. This was not our sole reason for ignoring the posterior probability distribution of future longitudinal data. Another was that POMDP algorithms suffer from the curse of dimensionality with continuous longitudinal outcomes~\citep{sunberg2018online}.

We also observed a more substantial drawback of POMDPs lying in their very flexible specification. Specifically, in a simple POMDP with binary test/no test decisions, and binary disease state (low-risk, progressed), it can be shown that there exist infinite possible rewards result in the same optimal schedule (Chapter~\ref{c4:appendix:pomdp}). Typically POMDP rewards are chosen based on survey results~\citep{denton2018optimization} and translated as quality-adjusted life-years saved. However, with infinite optimal reward sets, any reward set can be cherry-picked, including those that correspond to (improbable) thousands of quality-adjusted life-years saved. Hence, POMDPs may find the most optimal schedule, but to achieve that, the choice of suitable rewards is tough in practice.

\paragraph{Utility function: Euclidean distance, Parameters of interest: expected number of tests and time delay in detecting progression} Motivated by the POMDP framework we improved over planning one future test at a time (Chapter~\ref{c2}~and~\ref{c3}), by replacing it with a whole schedule of tests planned until a maximum future time point (e.g., end of the study period) in Chapter~\ref{c4}. To this end, we made risk threshold based test decisions iteratively at each future follow-up visit (e.g., future visits for biomarker measurement) of the patient. An important question, in this case, is which risk threshold yields the optimal schedule? To assist patients and doctors in this endeavor, we proposed a utility function to find the optimal risk threshold based schedule. The utility function was the Euclidean distance between a risk-based schedule and a perfect schedule (one test planned at the exact time of progression) in a bi-dimensional space of the expected number of tests and time delay in detecting progression. While we included only risk-based schedules in the Euclidean space, given $L$ future visits of a patient, the Euclidean distance can be used to find the optimal schedule among all $2^L$ possible schedules.

The main advantage of this approach is that we directly minimize quantities that manifest burden and benefit. Second, personalized schedules get updated with newly collected data over follow-up. Third, Euclidean distance is easier to understand compared to squared loss or the recursive POMDP value function. A drawback of our approach is that we are only able to schedule tests up to a maximum horizon time. Another caveat is that a fair comparison of time delays between different schedules for the same patient requires a compulsory test at a common horizon time point in all schedules.

\subsection{Criteria for Comparison of Schedules}
An important question for patients and doctors is if personalized schedules are any better than fixed schedules. Especially if personalized schedules improve upon patient deaths and/or progression to an advanced disease state (e.g., metastasis) compared to fixed schedules. However, to our knowledge, currently, there are no running studies that compare personalized versus fixed schedules. Also, reliable data on the number of patient deaths are difficult to obtain in low-grade diseases. This is because, in such diseases, the prevalence of death from disease can be quite low. For example, in the PRIAS prostate cancer dataset, only two out of 7813 patients were reported to die from prostate cancer.

In search of the criteria for comparison of schedules, in Chapter~\ref{c4:subsec:kappa_selection} we proposed a method to calculate expected number of tests (burden) per schedule and expected time delay in detecting progression (shorter is beneficial) for any schedule, fixed or personalized. These two are easily-quantifiable surrogates for important clinical aspects, such as the window of opportunity for curative treatment, risk of adverse downstream outcomes, quality-adjusted remaining lifetime, and additional complications in treating a delayed progression. Based on these two quantities, patients/doctors can compare any schedule with any other and decide which schedule suits them best. Both expected number of tests and expected time delay in detecting progression are calculated in a personalized manner. That is, two patients may be prescribed the exact same schedule of tests, but their expected time delay in detecting progression and the expected number of tests will depend on their disease progression risk profile.

\subsection{Factors Affecting Performance of Personalized Schedules}
We utilized the estimated cumulative-risk of disease progression for developing personalized schedules throughout this work. Thus, how accurately this risk profile resembles the actual disease state dictates the performance of the personalized schedules. In this regard, both the quality of the clinical data and the accuracy of the model are important. For example, in the prostate cancer surveillance scenario, we found that prostate-specific antigen (PSA) and its derivatives, such as PSA velocity, were not very strong predictors of progression (Chapter~\ref{c5}). Besides, the PSA measurement error was best modeled with a t-distribution with three degrees of freedom. As a result, until a rise in PSA was evident via multiple observations and the surge was sharp as well, the predicted risk profile remained almost the same. Another effect of this was that once a negative result was obtained on a biopsy, a patient's predicted risk remained low until PSA consistently showed a sharp rise. Consequently, our model discriminated poorly (Chapter~\ref{c5:appendix:validation_res}) between patients who obtained progression versus patients who did not obtain progression within a short time period of their last biopsy (e.g., an year). Overall, while building a model for personalized schedules, the focus should be on predictive ability of the model.

\subsection{Reusing a Test Scheduling Framework Across Different Cohorts and Diseases}
The utility functions and methodology we developed in this work is generic for scheduling tests in both screening and surveillance scenarios. It is also not necessary to rely only on joint models. The proposed utility functions only require an estimate of cumulative-risk of progression. While we focused on balancing the number of tests and time delay in detecting progression, users can extend the proposed methodology to include other aspects such as quality-adjusted life years. Our methodology may work differently in certain diseases. For example, in Barrett's esophagus~\citep{choi2012screening}, longitudinal data (e.g., p53 and SOX2 protein expressions) is collected when endoscopy (invasive test) is conducted. Consequently, risk predictions and personalized schedules do not update unless a test is conducted. Based on our findings from validation of the PRIAS (prostate cancer data introduced in Chapter~\ref{c1:subsec:PRIAS}) based model in external datasets (Chapter~\ref{c5:appendix:validation_res}), a model may require recalibration (e.g., of baseline-risk) before reusing in other cohorts. Alternatively, one may fit a new model to the new cohort before using the model for personalized schedules.